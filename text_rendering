Text renderer consumes:
	- a number of text sheets
		-> single texture  with a CHAR to CELLXY map.

class rectangle
{
	float x, y, w, h;
}

character_sheet
{
public:
	character_sheet(pTexture, map<wchar, rectangle> charmap)
	: m_pTexture(pTexture)
	, m_CharacterToUV(charmap)
	{}

private:
	shared_ptr<Texture> m_pTexture;

	// This structure allows for irregular placement and sizing of glyphs. Is this necessary? Maybe. I can imagine a low res render, chinese characters cant go as low as roman
	// so could lead to a mix resolution output.
	unordered_map<wchar, rectangle> m_CharacterToUV;
}
---
to support fonts (truetype etc), could be a higher level abstraction. so no need to further complicate this.

std::vector<character_sheet> rasterize_from_truetype(const byte *pTrueTypeFileBuffer, const size_t max_texture_size)
{
	vector<character_sheet> sheets;

	// 1 render all the glyphs
	stb_truetype....

	// 2 create textures by packing glyph rasters together
	stb_rectangle....

	return sheets;
}
--
so the important thing is that the text renderer can accomodate
	- any number of sheets

i can think of two strategies after this. 
1) 
	at construction time, create as many entities as there are sheets,
	then rendering is spread across the entities. 
	PRO: can use a very simple shader that can be used for other things
	CON: not taking advantage of the # of texture units available on the hardware

2)
	same as 1 except provide a custom shader that samples from many textures, then # of entities will be less. yes this is it, but must be hidden in impl
	-> is there a gl function to ask the implementation for the max_texture_units? if so then could even generate the shader source to use that many samplers.
